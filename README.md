# transformer-scratch
Creating transformer from scratch using pytorch and learning from hkproj (Umar Jamil)

https://github.com/hkproj/pytorch-transformer

In this repo, I'll be following step-by-step implementation by hkproj. Just modified somethings such as training and validation percentage, the numbers of sequence length, and the dataset that i train. This is just a learning repo,where me, a noobie in all of this trying to grab some knowledge that i can.

# You-Tube tutorial
https://www.youtube.com/watch?v=ISNdQcPhsts&list=WL&index=64&t=4600s

i' ll be updating this repo with malay dataset soon.

You can clone this repo and train your own transformer from scratch model using opus-books dataset.
# HuggingFace Opus Books Dataset
https://huggingface.co/datasets/opus_books


You can just change everything in the config.py page. I think Umar Jamil is not very clear on this.Please ensure that your sequence length is the same or more than your downloaded dataset.


